# -*- coding: utf-8 -*-
"""DSC253_HW2_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vqMNjWkNXVkerxw_t5VZs_CinyFYwaCH
"""

!git clone https://github.com/shangjingbo1226/AutoPhrase.git

!cd AutoPhrase/ && ./auto_phrase.sh

!cd AutoPhrase/ && ./phrasal_segmentation.sh

import re

def parse_segmented_corpus(input_file, output_file):
    sentences = []

    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            # Replace phrases with a single token (remove <phrase> tags and replace spaces with underscores)
            cleaned_line = re.sub(r'<phrase_Q=[^>]+>([^<]+)</phrase>', lambda m: m.group(1).replace(' ', '_'), line)
            sentences.append(cleaned_line.split())

    # Write the parsed corpus into a new file
    with open(output_file, 'w', encoding='utf-8') as out_f:
        for sentence in sentences:
            out_f.write(" ".join(sentence) + "\n")

    return sentences

parsed_sentences = parse_segmented_corpus('/content/segmentation.txt', 'parsed_corpus.txt')

print(parsed_sentences[0])

print(parsed_sentences[10])

from gensim.models import Word2Vec

model = Word2Vec(parsed_sentences, vector_size=100, window=5, min_count=5, workers=4)

model.save("word2vec_phrases_parsed.model")

import numpy as np
model = Word2Vec.load("/content/word2vec_phrases_parsed.model")

phrases = list(model.wv.index_to_key)
embeddings = np.array([model.wv[phrase] for phrase in phrases])

phrases[:30]

from sklearn.cluster import KMeans

# Set number of clusters to 6
kmeans = KMeans(n_clusters=6, random_state=42)
kmeans.fit(embeddings)

# Get cluster labels
kmeans_labels = kmeans.labels_

from sklearn.mixture import GaussianMixture

# Fit a Gaussian Mixture Model with 6 components (clusters)
gmm = GaussianMixture(n_components=6, random_state=42)
gmm.fit(embeddings)

# Get cluster labels
gmm_labels = gmm.predict(embeddings)

def print_cluster_phrases(phrases, labels, method_name, cluster_num=6, num_phrases=20):
    for i in range(cluster_num):
        print(f"\nCluster {i+1} - {method_name}:")
        cluster_phrases = [phrases[j] for j in range(len(phrases)) if labels[j] == i]
        print(cluster_phrases[:num_phrases])  # Print top 20 phrases from each cluster

# Print results for K-Means
print_cluster_phrases(phrases, kmeans_labels, 'K-Means')

print_cluster_phrases(phrases, gmm_labels, 'GMM')

